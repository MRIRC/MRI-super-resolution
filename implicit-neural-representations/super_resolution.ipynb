{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super resolution with implicit neural representations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nn_mri import ImageFitting_set, Siren, get_mgrid, cases, calculate_contrast, save_dicom\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "\n",
    "seg = 50\n",
    "scale = 1\n",
    "total_steps = 3000\n",
    "radius =5\n",
    "color = (255, 0, 0)\n",
    "thickness = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Directional approach\n",
    "## Training a separate NN for each of the x, y and z directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repeat the process 5 times and observe the difference w.r.t. the contrast and CNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_steps = 3000\n",
    "gland_start = 0\n",
    "focus_size = 128\n",
    "show_cancer = False\n",
    "weighted = False\n",
    "display = False\n",
    "do_detection = False\n",
    "sigma_est = 2\n",
    "scale = 1\n",
    "patch_kw = dict(patch_size=3,      # 5x5 patches\n",
    "                patch_distance=3)\n",
    "metrics = ['C', 'CNR']\n",
    "filename = '../experiments/f.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write('seed,patient,direction,epoch,image,metric,performance\\n')\n",
    "\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    for case in cases:\n",
    "        _slice = case.cancer_slice\n",
    "        if show_cancer : #TODO add titles and pt_id descriptions\n",
    "            orig = case.dwi[:, :, _slice, :].mean(-1)\n",
    "            center_coordinates = case.cancer_loc[::-1]\n",
    "            height, width = orig.shape\n",
    "            img = orig\n",
    "            img = gray2rgb(img*255/img.max())\n",
    "            img = np.ascontiguousarray(img, dtype=np.uint8)\n",
    "\n",
    "            cv2.circle(img, center_coordinates, radius, color, thickness)\n",
    "            plt.figure()\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            \n",
    "        predicted_XYZ = []\n",
    "        original_XYZ = []\n",
    "        directions = ['x', 'y', 'z']\n",
    "        for direction in range(3):  # gradient directions x, y, z\n",
    "            ends = np.cumsum(case.acquisitions)\n",
    "            starts = ends - case.acquisitions\n",
    "            \n",
    "            # Create a dataset for training SIREN\n",
    "            img_dataset = []\n",
    "            for acq in range(starts[direction], ends[direction]):\n",
    "                img = case.dwi[gland_start : gland_start + focus_size,\n",
    "                               gland_start : gland_start + focus_size,\n",
    "                               _slice,\n",
    "                               acq]\n",
    "                img_dataset.append(Image.fromarray(img))\n",
    "\n",
    "            dataset = ImageFitting_set(img_dataset)\n",
    "            orig = dataset.mean\n",
    "            pt_no = case.pt_id.split('-')[-1]\n",
    "\n",
    "                \n",
    "            original_XYZ.append(orig)\n",
    "            dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "            img_siren = Siren(in_features=2, out_features=1, hidden_features=128, \n",
    "                         hidden_layers=2, outermost_linear=True)\n",
    "            img_siren.cuda()\n",
    "            torch.cuda.empty_cache()\n",
    "            optim = torch.optim.Adam(lr=0.0003, params=img_siren.parameters())\n",
    "            ctr = 0\n",
    "            for step in tqdm(range(total_steps)):\n",
    "                size = dataset.shape\n",
    "                for sample in range(len(dataset)):                    \n",
    "                    ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "                    ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "                    model_output, coords = img_siren(model_input)\n",
    "                    if weighted:\n",
    "                        weights = ground_truth/ground_truth.sum()\n",
    "                        weights -= weights.min()\n",
    "                        weights += 0.000001\n",
    "                    else:\n",
    "                        weights = 1\n",
    "                    loss = weights*(model_output - ground_truth)**2\n",
    "                    loss = loss.mean()\n",
    "                    optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "                if not step % seg:\n",
    "                    coords2 = get_mgrid(size[0]*scale, 2).cuda()\n",
    "                    superres, _ = img_siren(coords2)\n",
    "                    pr = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                    if ctr < 50:\n",
    "                        predicted = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                        out_img = predicted\n",
    "                    else:\n",
    "                        predicted += superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                        out_img = predicted/(ctr-49)\n",
    "                    ctr += 1\n",
    "                    nlm = denoise_nl_means(out_img, h=1.15 * sigma_est, fast_mode=True, **patch_kw)\n",
    "                    orig2 = rescale(orig, scale, anti_aliasing=False)\n",
    "                    images = {'mean':orig2, 'reconst':pr, 'superres':out_img, 'NLM':nlm}\n",
    "\n",
    "                    with open(filename, 'a') as f:\n",
    "                        for image in images.keys():\n",
    "                            for inx, metric in enumerate(metrics):\n",
    "                                f.write('{},{},{},{},{},{},{}\\n'.format(seed, pt_no, directions[direction], step,\n",
    "                                                                        image, metric,\n",
    "                                                                        calculate_contrast(case, \n",
    "                                                                                           scale,\n",
    "                                                                                           images[image],\n",
    "                                                                                           gland_start)[inx]))\n",
    "\n",
    "            predicted_XYZ.append(out_img)\n",
    "            \n",
    "        predicted = sum(predicted_XYZ)/len(predicted_XYZ)\n",
    "        orig = sum(original_XYZ)/len(original_XYZ)    \n",
    "        noisy = predicted\n",
    "        denoise = denoise_nl_means(noisy, h=1.15 * sigma_est, fast_mode=False,\n",
    "                                       **patch_kw)\n",
    "        nlm = denoise\n",
    "        out_img = noisy\n",
    "        with open(filename, 'a') as f:\n",
    "            for image in images.keys():\n",
    "                for inx, metric in enumerate(metrics):\n",
    "                    f.write('{},{},{},{},{},{},{}\\n'.format(seed, pt_no, 'x+y+z', ((total_steps-1)//seg)*seg,\n",
    "                                                            image, metric,\n",
    "                                                            calculate_contrast(case,\n",
    "                                                                               scale,\n",
    "                                                                               images[image],\n",
    "                                                                               gland_start)[inx]))\n",
    "\n",
    "        if display:\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 15),\n",
    "                                   sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "            ax[0].imshow(rescale(orig, scale, anti_aliasing=False), cmap='gray')\n",
    "            ax[0].axis('off')\n",
    "            ax[0].set_title('original')\n",
    "            ax[1].imshow(noisy, cmap='gray')\n",
    "            ax[1].axis('off')\n",
    "            ax[1].set_title('superres')\n",
    "            ax[2].imshow(denoise, cmap='gray')\n",
    "            ax[2].axis('off')\n",
    "            ax[2].set_title('superres + NLM')\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        if do_detection:\n",
    "            a = rescale(orig, 1, anti_aliasing=True)\n",
    "            denoise_fast = denoise_nl_means(a, h=0.8 * sigma_est, fast_mode=True,\n",
    "                                            **patch_kw)\n",
    "            (thresh, blackAndWhiteImage) = cv2.threshold(a, a.max()*0.95, 255, cv2.THRESH_BINARY)\n",
    "            (thresh, blackAndWhiteImage2) = cv2.threshold(noisy, noisy.max()*0.95, 255, cv2.THRESH_BINARY)\n",
    "            (thresh, blackAndWhiteImage3) = cv2.threshold(denoise, denoise.max()*0.95, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 15),\n",
    "                                   sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "            ax[0].imshow(rescale(a, scale, anti_aliasing=False), cmap='gray')\n",
    "            ax[0].imshow(rescale(blackAndWhiteImage, scale, anti_aliasing=True), 'hot',alpha=0.5)\n",
    "            ax[0].axis('off')\n",
    "            ax[0].axis('off')\n",
    "            ax[0].set_title('original')\n",
    "\n",
    "            ax[1].imshow(noisy, cmap='gray')\n",
    "            ax[1].imshow(blackAndWhiteImage2,'hot', alpha=0.5)\n",
    "            ax[1].axis('off')\n",
    "            ax[1].axis('off')\n",
    "            ax[1].set_title('superres')\n",
    "            ax[2].imshow( denoise, cmap='gray')\n",
    "            ax[2].imshow(blackAndWhiteImage3, 'hot', alpha=0.5)\n",
    "            ax[2].axis('off')\n",
    "            ax[2].set_title('superres + NLM')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save 3X reconstruction images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_steps = 3000\n",
    "gland_start = 0\n",
    "focus_size = 128\n",
    "scale = 3\n",
    "show_cancer = False\n",
    "weighted = False\n",
    "display = True\n",
    "sigma_est = 2\n",
    "patch_kw = dict(patch_size=3,      # 5x5 patches\n",
    "                patch_distance=3)\n",
    "\n",
    "out_folder = '../output_images/'\n",
    "\n",
    "for case in cases:\n",
    "    _slice = case.cancer_slice\n",
    "    if show_cancer : #TODO add titles and pt_id descriptions\n",
    "        orig = case.dwi[:, :, _slice, :].mean(-1)\n",
    "        center_coordinates = case.cancer_loc[::-1]\n",
    "        height, width = orig.shape\n",
    "        img = orig\n",
    "        img = gray2rgb(img*255/img.max())\n",
    "        img = np.ascontiguousarray(img, dtype=np.uint8)\n",
    "\n",
    "        cv2.circle(img, center_coordinates, radius, color, thickness)\n",
    "        plt.figure()\n",
    "        plt.imshow(img, cmap='gray')\n",
    "\n",
    "    predicted_XYZ = []\n",
    "    original_XYZ = []\n",
    "    directions = ['x', 'y', 'z']\n",
    "    for direction in range(3):  # gradient directions x, y, z\n",
    "        ends = np.cumsum(case.acquisitions)\n",
    "        starts = ends - case.acquisitions\n",
    "\n",
    "        # Create a dataset for training SIREN\n",
    "        img_dataset = []\n",
    "        for acq in range(starts[direction], ends[direction]):\n",
    "            img = case.dwi[gland_start : gland_start + focus_size,\n",
    "                           gland_start : gland_start + focus_size,\n",
    "                           _slice,\n",
    "                           acq]\n",
    "            img_dataset.append(Image.fromarray(img))\n",
    "\n",
    "        dataset = ImageFitting_set(img_dataset)\n",
    "        orig = dataset.mean\n",
    "        pt_no = case.pt_id.split('-')[-1]\n",
    "\n",
    "        original_XYZ.append(orig)\n",
    "        dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "        img_siren = Siren(in_features=2, out_features=1, hidden_features=128, \n",
    "                     hidden_layers=2, outermost_linear=True)\n",
    "        img_siren.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "        optim = torch.optim.Adam(lr=0.0003, params=img_siren.parameters())\n",
    "        ctr = 0\n",
    "        for step in range(total_steps):\n",
    "            size = dataset.shape\n",
    "            for sample in range(len(dataset)):                    \n",
    "                ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "                ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "                model_output, coords = img_siren(model_input)\n",
    "                if weighted:\n",
    "                    weights = ground_truth/ground_truth.sum()\n",
    "                    weights -= weights.min()\n",
    "                    weights += 0.000001\n",
    "                else:\n",
    "                    weights = 1\n",
    "                loss = weights*(model_output - ground_truth)**2\n",
    "                loss = loss.mean()\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            if not step % seg:\n",
    "                coords2 = get_mgrid(size[0]*scale, 2).cuda()\n",
    "                superres, _ = img_siren(coords2)\n",
    "                pr = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                if ctr < 50:\n",
    "                    predicted = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                    out_img = predicted\n",
    "                else:\n",
    "                    predicted += superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                    out_img = predicted/float(ctr-49)\n",
    "                ctr += 1\n",
    "                nlm = denoise_nl_means(out_img, h=1.15 * sigma_est, fast_mode=True, **patch_kw)\n",
    "\n",
    "\n",
    "        predicted_XYZ.append(out_img)\n",
    "        filename = os.path.join(out_folder, 'sr1_exp_1_' + pt_no + '_mean_' + directions[direction] + '_wide.dcm')\n",
    "        save_dicom(orig, filename)\n",
    "        filename = os.path.join(out_folder, 'sr1_exp_1_' + pt_no + '_super_' + directions[direction] + '_wide.dcm')\n",
    "        save_dicom(out_img, filename)\n",
    "\n",
    "    \n",
    "    predicted = sum(predicted_XYZ)/len(predicted_XYZ)\n",
    "    orig = sum(original_XYZ)/len(original_XYZ)\n",
    "    \n",
    "    nlm = denoise_nl_means(predicted, h=1.15 * sigma_est, fast_mode=False,\n",
    "                                   **patch_kw)\n",
    "\n",
    "    filename = os.path.join(out_folder, 'sr1_exp_1_' + pt_no + '_mean_wide.dcm')\n",
    "    save_dicom(orig, filename)\n",
    "    filename = os.path.join(out_folder, 'sr1_exp_1_' + pt_no + '_super_wide.dcm')\n",
    "    save_dicom(predicted, filename)\n",
    "    filename = os.path.join(out_folder, 'sr1_exp_1_' + pt_no + '_NLM_wide.dcm')\n",
    "    save_dicom(nlm, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use all acquisitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = '../experiments/'\n",
    "\n",
    "total_steps = 3000\n",
    "seg = 50\n",
    "gland_start = 40\n",
    "focus_size = 50\n",
    "weighted = True\n",
    "sigma_est = 2\n",
    "hidden_layers = 2\n",
    "hidden_features = 128\n",
    "scale = 1\n",
    "patch_kw = dict(patch_size=3, patch_distance=3)\n",
    "\n",
    "metrics = ['C', 'CNR']\n",
    "\n",
    "method_name = 'sr1'\n",
    "exp_no = 5\n",
    "filename = os.path.join(out_folder, method_name + '_exp_' + str(exp_no) + '.csv')\n",
    "with open(filename, 'w') as f:\n",
    "    f.write('seed,patient,direction,epoch,image,metric,performance\\n')\n",
    "\n",
    "\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    for case in cases:\n",
    "        _slice = case.cancer_slice\n",
    "        ends =sum(case.acquisitions)\n",
    "            \n",
    "        # Create a dataset for training SIREN\n",
    "        img_dataset = []\n",
    "        for acq in range(ends):\n",
    "            img = case.dwi[gland_start : gland_start + focus_size,\n",
    "                           gland_start : gland_start + focus_size,\n",
    "                           _slice,\n",
    "                           acq]\n",
    "            img_dataset.append(Image.fromarray(img))\n",
    "\n",
    "        dataset = ImageFitting_set(img_dataset)\n",
    "        orig = dataset.mean\n",
    "        pt_no = case.pt_id.split('-')[-1]\n",
    "\n",
    "        dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "        img_siren = Siren(in_features=2, out_features=1, hidden_features=128, hidden_layers=2)\n",
    "        img_siren.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "        optim = torch.optim.Adam(lr=0.0003, params=img_siren.parameters())\n",
    "        ctr = 0\n",
    "        for step in tqdm(range(total_steps)):\n",
    "            size = dataset.shape\n",
    "            for sample in range(len(dataset)):                    \n",
    "                ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "                ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "                model_output, coords = img_siren(model_input)\n",
    "                weights = 1\n",
    "                loss = weights*(model_output - ground_truth)**2\n",
    "                loss = loss.mean()\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            if not step % seg:\n",
    "                coords2 = get_mgrid(size[0]*scale, 2).cuda()\n",
    "                superres, _ = img_siren(coords2)\n",
    "                pr = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                if ctr < 5:\n",
    "                    predicted = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                    out_img = predicted\n",
    "                else:\n",
    "                    predicted += superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                    out_img = predicted/(ctr-4)\n",
    "                ctr += 1\n",
    "                nlm = denoise_nl_means(out_img, h=1.15 * sigma_est, fast_mode=True, **patch_kw)\n",
    "                orig2 = rescale(orig, scale, anti_aliasing=False)\n",
    "                images = {'mean':orig2, 'reconst':pr, 'superres':out_img, 'NLM':nlm}\n",
    "\n",
    "                with open(filename, 'a') as f:\n",
    "                    for image in images.keys():\n",
    "                        for inx, metric in enumerate(metrics):\n",
    "                            f.write('{},{},{},{},{},{},{}\\n'.format(seed, pt_no, 'all', step,\n",
    "                                                                    image, metric,\n",
    "                                                                    calculate_contrast(case, \n",
    "                                                                                       scale,\n",
    "                                                                                       images[image],\n",
    "                                                                                       gland_start)[inx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = 3000\n",
    "gland_start = 0\n",
    "focus_size = 128\n",
    "show_cancer = True\n",
    "weighted = False\n",
    "display = False\n",
    "do_detection = False\n",
    "sigma_est = 2\n",
    "scale = 1\n",
    "patch_kw = dict(patch_size=3,      # 5x5 patches\n",
    "                patch_distance=3)\n",
    "metrics = ['C', 'CNR']\n",
    "filename = '../experiments/f.csv'\n",
    "with open(filename, 'w') as f:\n",
    "    f.write('seed,patient,direction,epoch,image,metric,performance\\n')\n",
    "\n",
    "\n",
    "for case in cases:\n",
    "    _slice = case.cancer_slice\n",
    "    if show_cancer : #TODO add titles and pt_id descriptions\n",
    "        orig = case.dwi[:, :, _slice, :].mean(-1)\n",
    "        center_coordinates = case.cancer_loc[::-1]\n",
    "        height, width = orig.shape\n",
    "        img = orig\n",
    "        img = gray2rgb(img*255/img.max())\n",
    "        img = np.ascontiguousarray(img, dtype=np.uint8)\n",
    "\n",
    "        cv2.circle(img, center_coordinates, radius, color, thickness)\n",
    "        plt.figure()\n",
    "        plt.title(case.pt_id)\n",
    "        plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "total_steps = 3000\n",
    "gland_start = 0\n",
    "focus_size = 128\n",
    "scale = 3\n",
    "show_cancer = False\n",
    "weighted = False\n",
    "display = True\n",
    "sigma_est = 2\n",
    "patch_kw = dict(patch_size=3,      # 5x5 patches\n",
    "                patch_distance=3)\n",
    "\n",
    "out_folder = '../output_images/'\n",
    "\n",
    "pt_id = '18-1681-08'\n",
    "cancer_loc = (79, 71)\n",
    "collateral_loc = (79, 59)\n",
    "cancer_slice = 10\n",
    "acquisitions = (8, 7, 8)\n",
    "pt_no = pt_id.split('-')[-1]\n",
    "filename = '../anon_data/pat' + pt_no + '_alldata.mat'\n",
    "dwi = sio.loadmat(filename)['data']\n",
    "filename = '../anon_data/pat' + pt_no + '_mean_b0.mat'\n",
    "b0 = sio.loadmat(filename)['data_mean_b0']\n",
    "filename = '../anon_data/pat' + pt_no + '_ADC_alldata_mm.mat'\n",
    "adc = sio.loadmat(filename)['ADC_alldata_mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adc[:, : ,cancer_slice, :].mean(-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b0[:, :, cancer_slice], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1500 = dwi[:, : ,cancer_slice, :].mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc = -np.log(mean_1500/(b0[:, :, cancer_slice] + 1e-7))\n",
    "adc /=1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_XYZ = []\n",
    "directions = ['x', 'y', 'z']\n",
    "for direction in range(3):  # gradient directions x, y, z\n",
    "    ends = np.cumsum(acquisitions)\n",
    "    starts = ends - acquisitions\n",
    "\n",
    "    # Create a dataset for training SIREN\n",
    "    img_dataset = []\n",
    "    for acq in range(starts[direction], ends[direction]):\n",
    "        img = dwi[gland_start : gland_start + focus_size,\n",
    "                       gland_start : gland_start + focus_size,\n",
    "                       cancer_slice,\n",
    "                       acq]\n",
    "        img_dataset.append(Image.fromarray(img))\n",
    "\n",
    "    dataset = ImageFitting_set(img_dataset)\n",
    "    orig = dataset.mean\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "    img_siren = Siren(in_features=2, out_features=1, hidden_features=128, \n",
    "                 hidden_layers=2)\n",
    "    img_siren.cuda()\n",
    "    torch.cuda.empty_cache()\n",
    "    optim = torch.optim.Adam(lr=0.0003, params=img_siren.parameters())\n",
    "    ctr = 0\n",
    "    for step in range(total_steps):\n",
    "        size = dataset.shape\n",
    "        for sample in range(len(dataset)):                    \n",
    "            ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "            ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "            model_output, coords = img_siren(model_input)\n",
    "            if weighted:\n",
    "                weights = ground_truth/ground_truth.sum()\n",
    "                weights -= weights.min()\n",
    "                weights += 0.000001\n",
    "            else:\n",
    "                weights = 1\n",
    "            loss = weights*(model_output - ground_truth)**2\n",
    "            loss = loss.mean()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        if not step % seg:\n",
    "            coords2 = get_mgrid(size[0]*scale, 2).cuda()\n",
    "            superres, _ = img_siren(coords2)\n",
    "            pr = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "            if ctr < 50:\n",
    "                predicted = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                out_img = predicted\n",
    "            else:\n",
    "                predicted += superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "                out_img = predicted/float(ctr-49)\n",
    "            ctr += 1\n",
    "            nlm = denoise_nl_means(out_img, h=1.15 * sigma_est, fast_mode=True, **patch_kw)\n",
    "\n",
    "\n",
    "    predicted_XYZ.append(out_img)\n",
    "\n",
    "predicted = sum(predicted_XYZ)/len(predicted_XYZ)\n",
    "\n",
    "\n",
    "nlm = denoise_nl_means(predicted, h=1.15 * sigma_est, fast_mode=False,\n",
    "                               **patch_kw)\n",
    "\n",
    "\n",
    "filename = os.path.join(out_folder, 'sr1_exp_5_' + pt_no + '_super_wide.dcm')\n",
    "save_dicom(predicted, filename)\n",
    "filename = os.path.join(out_folder, 'sr1_exp_5_' + pt_no + '_NLM_wide.dcm')\n",
    "save_dicom(nlm, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = sum(predicted_XYZ)/len(predicted_XYZ)\n",
    "\n",
    "\n",
    "nlm = denoise_nl_means(predicted, h=1.15 * sigma_est, fast_mode=False,\n",
    "                               **patch_kw)\n",
    "\n",
    "scale = 3\n",
    "filename = os.path.join(out_folder, 'sr1_exp_5_' + pt_no + '_super.dcm')\n",
    "save_dicom(predicted, filename)\n",
    "\n",
    "b0_dataset = []\n",
    "img = b0[gland_start : gland_start + focus_size,\n",
    "                   gland_start : gland_start + focus_size,\n",
    "                   cancer_slice]\n",
    "b0_dataset.append(Image.fromarray(img))\n",
    "\n",
    "dataset = ImageFitting_set(b0_dataset)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "img_siren = Siren(in_features=2, out_features=1, hidden_features=128, \n",
    "             hidden_layers=2)\n",
    "img_siren.cuda()\n",
    "torch.cuda.empty_cache()\n",
    "optim = torch.optim.Adam(lr=0.0003, params=img_siren.parameters())\n",
    "ctr = 0\n",
    "for step in range(24000):\n",
    "    size = dataset.shape\n",
    "    for sample in range(len(dataset)):                    \n",
    "        ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "        ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "        model_output, coords = img_siren(model_input)\n",
    "        if weighted:\n",
    "            weights = ground_truth/ground_truth.sum()\n",
    "            weights -= weights.min()\n",
    "            weights += 0.000001\n",
    "        else:\n",
    "            weights = 1\n",
    "        loss = weights*(model_output - ground_truth)**2\n",
    "        loss = loss.mean()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    if not step % seg:\n",
    "        coords2 = get_mgrid(size[0]*scale, 2).cuda()\n",
    "        superres, _ = img_siren(coords2)\n",
    "        pr = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "        if ctr < 5:\n",
    "            _predicted = superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "            out_img = _predicted\n",
    "        else:\n",
    "            _predicted += superres.cpu().view(scale*size[0], scale* size[1]).detach().numpy()\n",
    "            out_img = _predicted/float(ctr-4)\n",
    "        ctr += 1\n",
    "        nlm = denoise_nl_means(out_img, h=1.15 * sigma_est, fast_mode=True, **patch_kw)\n",
    "    \n",
    "\n",
    "filename = os.path.join(out_folder, 'sr1_exp_5_' + pt_no + '_super_b0.dcm')\n",
    "save_dicom(out_img, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(out_folder, 'sr1_exp_5_' + pt_no + '_b0.dcm')\n",
    "save_dicom(img, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted -= predicted.min()\n",
    "out_img -= out_img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc = -np.log(predicted/(out_img + 1e-7))\n",
    "adc /=9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(adc, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(out_folder, 'sr1_exp_5_' + pt_no + '_adc.dcm')\n",
    "save_dicom(adc[:,:, cancer_slice,:].mean(axis=-1), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../anon_data/pat' + pt_no + '_ADC_alldata_mm.mat'\n",
    "adc = sio.loadmat(filename)['ADC_alldata_mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adc[:,:, cancer_slice,:].mean(axis=-1), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
