{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m random_noise\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransform\u001b[39;00m \u001b[39mimport\u001b[39;00m rescale, resize, downscale_local_mean\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m AgglomerativeClustering\n\u001b[1;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msio\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[0;32m~/inr3/lib64/python3.9/site-packages/sklearn/cluster/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mThe :mod:`sklearn.cluster` module gathers popular unsupervised clustering\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39malgorithms.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_spectral\u001b[39;00m \u001b[39mimport\u001b[39;00m spectral_clustering, SpectralClustering\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_mean_shift\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_shift, MeanShift, estimate_bandwidth, get_bin_seeds\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_affinity_propagation\u001b[39;00m \u001b[39mimport\u001b[39;00m affinity_propagation, AffinityPropagation\n",
      "File \u001b[0;32m~/inr3/lib64/python3.9/site-packages/sklearn/cluster/_spectral.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_kernels, KERNEL_PARAMS\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m kneighbors_graph, NearestNeighbors\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanifold\u001b[39;00m \u001b[39mimport\u001b[39;00m spectral_embedding\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_kmeans\u001b[39;00m \u001b[39mimport\u001b[39;00m k_means\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcluster_qr\u001b[39m(vectors):\n",
      "File \u001b[0;32m~/inr3/lib64/python3.9/site-packages/sklearn/manifold/__init__.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_mds\u001b[39;00m \u001b[39mimport\u001b[39;00m MDS, smacof\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_spectral_embedding\u001b[39;00m \u001b[39mimport\u001b[39;00m SpectralEmbedding, spectral_embedding\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_t_sne\u001b[39;00m \u001b[39mimport\u001b[39;00m TSNE, trustworthiness\n\u001b[1;32m     11\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlocally_linear_embedding\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLocallyLinearEmbedding\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrustworthiness\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m ]\n",
      "File \u001b[0;32m~/inr3/lib64/python3.9/site-packages/sklearn/manifold/_t_sne.py:29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m pairwise_distances, _VALID_METRICS\n\u001b[1;32m     28\u001b[0m \u001b[39m# mypy error: Module 'sklearn.manifold' has no attribute '_utils'\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _utils  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# mypy error: Module 'sklearn.manifold' has no attribute '_barnes_hut_tsne'\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _barnes_hut_tsne  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "from nn_mri import ImageFitting_set, SineLayer, get_mgrid\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "from torch import nn\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import argparse\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3661548087.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def input_mapping(x, B)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Fourier feature mapping\n",
    "def input_mapping(x, B):\n",
    "  if B is None:\n",
    "    return x\n",
    "  else:\n",
    "    x_proj = (2.*np.pi*x) @ B.T\n",
    "    return np.concatenate([np.sin(x_proj), np.cos(x_proj)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siren(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, \n",
    "                 hidden_layers, out_features, \n",
    "                 first_omega_0=30., \n",
    "                 hidden_omega_0=30.,\n",
    "                 perturb=False):\n",
    "        super().__init__()\n",
    "        # self.net is the INR that calculates signal intensities for its inputs\n",
    "        self.net = []\n",
    "        self.tanh = nn.Tanh()  \n",
    "        self.final_linear = nn.Linear(hidden_features, out_features)\n",
    "        with torch.no_grad():\n",
    "            self.final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
    "        self.net.append(SineLayer(in_features, hidden_features, is_first=True, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(SineLayer(hidden_features, hidden_features, is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        self.net.append(self.final_linear)\n",
    "\n",
    "        self.net = nn.Sequential(*self.net)\n",
    "        self.perturb_linear = nn.Linear(in_features + 1, in_features + 1)\n",
    "        self.perturb_linear2 = nn.Linear(in_features + 1, in_features)\n",
    "        \n",
    "        self.perturb = perturb\n",
    "        \n",
    "    def forward(self, coords, sample=0,eps=0):\n",
    "        coords = coords.clone().detach().requires_grad_(False) # allows to take derivative w.r.t. input\n",
    "        if self.perturb:\n",
    "            acq = torch.tensor([sample], dtype=torch.float).cuda()\n",
    "            acq = acq.repeat(coords.size(0),1)\n",
    "            perturbation = self.perturb_linear(torch.cat((coords, acq),-1))\n",
    "            perturbation = self.tanh(perturbation)\n",
    "            perturbation = self.perturb_linear2(perturbation)\n",
    "            pertubation = eps*self.tanh(perturbation)\n",
    "            coords = coords + pertubation\n",
    "        output = self.net(coords)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/gundogdu/toy2.mat'\n",
    "acquisitions = sio.loadmat(filename)['pertubed_acq']\n",
    "filename2 = '/home/gundogdu/nomo.mat'\n",
    "nomo = sio.loadmat(filename2)['x_sub']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduled INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m ground_truth, model_input \u001b[39m=\u001b[39m ground_truth\u001b[39m.\u001b[39mcuda(), model_input\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     32\u001b[0m ground_truth \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m ground_truth\u001b[39m.\u001b[39mmax()\n\u001b[0;32m---> 33\u001b[0m model_output \u001b[39m=\u001b[39m img_siren\u001b[39m.\u001b[39;49mforward(model_input)\n\u001b[1;32m     34\u001b[0m loss \u001b[39m=\u001b[39m ((model_output \u001b[39m-\u001b[39m ground_truth)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     35\u001b[0m inr_optim\u001b[39m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[25], line 41\u001b[0m, in \u001b[0;36mSiren.forward\u001b[0;34m(self, coords, sample, eps)\u001b[0m\n\u001b[1;32m     39\u001b[0m     coords \u001b[39m=\u001b[39m coords \u001b[39m+\u001b[39m pertubation\n\u001b[1;32m     40\u001b[0m B_gauss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(size\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmap_features\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m---> 41\u001b[0m input_to_the_model \u001b[39m=\u001b[39m input_mapping(coords, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB \u001b[39m*\u001b[39;49m B_gauss)\n\u001b[1;32m     42\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet(input_to_the_model)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m, in \u001b[0;36minput_mapping\u001b[0;34m(x, B)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m      5\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m   x_proj \u001b[39m=\u001b[39m (\u001b[39m2.\u001b[39;49m\u001b[39m*\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpi\u001b[39m*\u001b[39;49mx) \u001b[39m@\u001b[39;49m B\u001b[39m.\u001b[39;49mT\n\u001b[1;32m      7\u001b[0m   \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mconcatenate([torch\u001b[39m.\u001b[39msin(x_proj), torch\u001b[39m.\u001b[39mcos(x_proj)], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/inr3/lib64/python3.9/site-packages/torch/_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    969\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "mean_img = np.mean(acquisitions,-1)\n",
    "img_dataset = []\n",
    "for inx in range(acquisitions.shape[-1]):\n",
    "    img = acquisitions[:,:,inx]\n",
    "    img_dataset.append(Image.fromarray(img))\n",
    "\n",
    "mean_dataset = ImageFitting_set([Image.fromarray(mean_img)])\n",
    "dataset = ImageFitting_set(img_dataset)\n",
    "\n",
    "img_siren = Siren(in_features=2, out_features=1, \n",
    "                      hidden_features=128,\n",
    "                      hidden_layers=3, perturb=True)\n",
    "\n",
    "img_siren.cuda()\n",
    "\n",
    "inr_params = list(img_siren.net.parameters())\n",
    "inr_optim = torch.optim.Adam(lr=1e-4, params=inr_params)\n",
    "perturb_params = list(img_siren.perturb_linear.parameters()) + list(img_siren.perturb_linear2.parameters())\n",
    "perturb_optim = torch.optim.Adam(lr=1e-6, params=perturb_params)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "ctr = 0\n",
    "new_loss = 1000\n",
    "while True:\n",
    "    ctr += 1\n",
    "    if ctr < 4000:\n",
    "        ground_truth, model_input  = mean_dataset.pixels[0], mean_dataset.coords[0]\n",
    "        ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "        ground_truth /= ground_truth.max()\n",
    "        model_output = img_siren.forward(model_input)\n",
    "        loss = ((model_output - ground_truth)**2).mean()\n",
    "        inr_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        inr_optim.step()\n",
    "    else:\n",
    "        if ctr%2:\n",
    "            ground_truth, model_input  = mean_dataset.pixels[0], mean_dataset.coords[0]\n",
    "            ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "            ground_truth /= ground_truth.max()\n",
    "            model_output = img_siren.forward(model_input)\n",
    "            loss = ((model_output - ground_truth)**2).mean()\n",
    "            inr_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            inr_optim.step()\n",
    "        else:\n",
    "            for sample in range(len(dataset)):\n",
    "                ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "                ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "                ground_truth /= ground_truth.max()\n",
    "                model_output = img_siren.forward(model_input, sample, 1/128.)\n",
    "                if not sample:\n",
    "                    loss = ((model_output - ground_truth)**2).mean()\n",
    "                else:\n",
    "                    loss += ((model_output - ground_truth)**2).mean()\n",
    "        \n",
    "            perturb_optim.zero_grad()\n",
    "            loss.backward()\n",
    "            perturb_optim.step()\n",
    "        \n",
    "    if not ctr%1000:\n",
    "        print(new_loss)\n",
    "        model_input  = get_mgrid(256, 2).cuda()\n",
    "        recon = torch.clamp(img_siren.forward(model_input), min=0).cpu().view(256,256).detach().numpy()\n",
    "        fig, ax = plt.subplots(1,3,figsize=(18,6))\n",
    "        ax[0].imshow(recon, cmap='gray')\n",
    "        ax[0].set_title('super')\n",
    "        ax[1].imshow(rescale(nomo,2), cmap='gray')\n",
    "        ax[1].set_title('no-motion')\n",
    "        ax[2].imshow(rescale(mean_img,2), cmap='gray')\n",
    "        ax[2].set_title('mean')\n",
    "        for axi in range(3):\n",
    "            ax[axi].axis('off')\n",
    "\n",
    "        display.display(plt.gcf())\n",
    "    if loss.item() > new_loss and ctr>10000:\n",
    "        break      \n",
    "    else:\n",
    "        new_loss = loss.item()\n",
    "print('Done')\n",
    "\n",
    "PATH = 'toy_model.pt'\n",
    "torch.save(img_siren.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_dataset = []\n",
    "ctr = 0\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "img_siren = Siren(in_features=2, out_features=1, \n",
    "                      hidden_features=128,\n",
    "                      hidden_layers=3, perturb=True)\n",
    "img_siren.cuda()\n",
    "torch.cuda.empty_cache()\n",
    "PATH = 'toy_model.pt'\n",
    "img_siren.load_state_dict(torch.load(PATH))\n",
    "img_siren.cuda()\n",
    "\n",
    "\n",
    "params1 = list(img_siren.perturb_linear.parameters()) + list(img_siren.perturb_linear2.parameters())\n",
    "optim1 = torch.optim.Adam(lr=1e-4, params=params1)\n",
    "params2 = list(img_siren.net.parameters())\n",
    "optim2 = torch.optim.Adam(lr=1e-6, params=params2)\n",
    "ctr = 0\n",
    "new_loss = 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    for sample in range(len(dataset)):\n",
    "        ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "        ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "        ground_truth /= ground_truth.max()\n",
    "        model_output = img_siren.forward(model_input, sample, 4/720.)\n",
    "        if not sample:\n",
    "            loss = ((model_output - ground_truth)**2).mean()\n",
    "        else:\n",
    "            loss += ((model_output - ground_truth)**2).mean()\n",
    "    #optim1.zero_grad()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    #optim1.step()\n",
    "    optim.step()\n",
    "    if loss.item() > new_loss and ctr>100000:\n",
    "        break      \n",
    "    else:\n",
    "        new_loss = loss.item()\n",
    "    if not ctr%1000:\n",
    "        print(new_loss)\n",
    "        model_input  = get_mgrid(720, 2).cuda()\n",
    "        recon = img_siren.forward(model_input, 0, 4/720.0).cpu().view(720,720).detach().numpy()\n",
    "        fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "        ax[0].imshow(recon, cmap='gray')\n",
    "        ax[0].set_title('super')\n",
    "        ax[1].imshow(rescale(mean_img,4), vmin=0.6, vmax=1,cmap='gray')\n",
    "        ax[1].set_title('mean')\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "\n",
    "    ctr +=1\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat('output.mat', {'out':recon})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kiwi:\n",
    "    def __init__(self, img_id):\n",
    "\n",
    "        self.img_id = img_id\n",
    "        file_address = '/home/gundogdu/matfiles'\n",
    "        filename = os.path.join(file_address, img_id)\n",
    "        self.dwi = sio.loadmat(filename)['img']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_address = '/home/gundogdu/matfiles'\n",
    "kiwi_scans = []\n",
    "for f in os.listdir(file_address):\n",
    "    kiwi_scans.append(kiwi(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_kiwi = kiwi_scans[7]\n",
    "dwi = _kiwi.dwi[40:90,20:70]\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "ax.imshow(dwi, cmap='gray')\n",
    "ax.set_title(_kiwi.img_id)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = []\n",
    "mean_img = np.zeros(_kiwi.dwi[40:90,20:70].shape)\n",
    "ctr = 0\n",
    "for inx in range(len(kiwi_scans)):\n",
    "    _kiwi = kiwi_scans[inx]\n",
    "    if not 'high' in _kiwi.img_id and not 'motion' in _kiwi.img_id:\n",
    "        img = _kiwi.dwi[40:90,20:70]\n",
    "        mean_img += _kiwi.dwi[40:90,20:70]\n",
    "        ctr +=1\n",
    "        img_dataset.append(Image.fromarray(img))\n",
    "mean_img /= ctr\n",
    "dataset = ImageFitting_set(img_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "img_siren = Siren(in_features=2, out_features=1, \n",
    "                      hidden_features=64,\n",
    "                      hidden_layers=3, perturb=False)\n",
    "img_siren.cuda()\n",
    "torch.cuda.empty_cache()\n",
    "optim = torch.optim.Adam(lr=3e-4, params=img_siren.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_siren = Siren(in_features=2, out_features=1, \n",
    "                      hidden_features=64,\n",
    "                      hidden_layers=3, perturb=True)\n",
    "PATH = 'model.pt'\n",
    "img_siren.load_state_dict(torch.load(PATH))\n",
    "img_siren.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "params1 = list(img_siren.perturb_linear.parameters()) + list(img_siren.perturb_linear2.parameters())\n",
    "params2 = list(img_siren.net.parameters())\n",
    "perturb = True\n",
    "if perturb:\n",
    "    optim1 = torch.optim.Adam(lr=0.00001, params=params1)\n",
    "    optim2 = torch.optim.Adam(lr=0, params=params2)\n",
    "    perturb_degree = 1/100.\n",
    "else:\n",
    "    optim1 = torch.optim.Adam(lr=0, params=params1)\n",
    "    optim2 = torch.optim.Adam(lr=3e-4, params=params2)\n",
    "    perturb_degree = 0\n",
    "    \n",
    "ctr = 0\n",
    "new_loss = 1000\n",
    "\n",
    "\n",
    "while True:\n",
    "    for sample in range(len(dataset)):\n",
    "        ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "        ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "        ground_truth /= ground_truth.max()\n",
    "        model_output = img_siren.forward(model_input, sample, perturb_degree)\n",
    "        if not sample:\n",
    "            loss = ((model_output - ground_truth)**2).mean()\n",
    "        else:\n",
    "            loss += ((model_output - ground_truth)**2).mean()\n",
    "    if perturb:\n",
    "        optim1.zero_grad()\n",
    "    optim2.zero_grad()\n",
    "    loss.backward()\n",
    "    if perturb:\n",
    "        optim1.step()\n",
    "    optim2.step()\n",
    "    if loss.item() > new_loss and ctr>1000:\n",
    "        break      \n",
    "    else:\n",
    "        new_loss = loss.item()\n",
    "    if not ctr%500:\n",
    "        print(new_loss)\n",
    "        model_input  = get_mgrid(100, 2).cuda()\n",
    "        recon = img_siren.forward(model_input, 0, perturb_degree).cpu().view(100,100).detach().numpy()\n",
    "        fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "        ax[0].imshow(recon, cmap='gray')\n",
    "        ax[0].set_title('super')\n",
    "        ax[1].imshow(rescale(mean_img,2),cmap='gray')\n",
    "        ax[1].set_title('mean')\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "\n",
    "    ctr +=1\n",
    "print('Done')\n",
    "PATH = 'model.pt'\n",
    "torch.save(img_siren.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_siren = Siren(in_features=2, out_features=1, \n",
    "                      hidden_features=128,\n",
    "                      hidden_layers=3, perturb=True)\n",
    "PATH = 'model.pt'\n",
    "img_siren.load_state_dict(torch.load(PATH))\n",
    "img_siren.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_input  = get_mgrid(128, 2).cuda()\n",
    "recon = img_siren(model_input).cpu().view(128,128).detach().numpy()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
    "ax.imshow(recon, cmap='gray')\n",
    "ax.set_title('super')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recon = np.zeros((128,128))\n",
    "model_input  = get_mgrid(128, 2).cuda()\n",
    "for i in range(9):\n",
    "    model_output = img_siren(model_input, i, 1/64.0)\n",
    "    mean_recon += model_output.cpu().view(128,128).detach().numpy()\n",
    "mean_recon /= 9\n",
    "#model_input  = get_mgrid(128, 2).cuda()\n",
    "#model_output = img_siren(model_input).cpu().view((128,128)).detach().numpy()\n",
    "fig, ax = plt.subplots(13,1,figsize=(6,72))\n",
    "ax[0].imshow(mean_recon, cmap='gray')\n",
    "ax[0].set_title('super')\n",
    "ax[1].imshow(mean_img,cmap='gray')\n",
    "ax[1].set_title('mean')\n",
    "i=4\n",
    "for inx in range(len(kiwi_scans)):\n",
    "    _kiwi = kiwi_scans[inx]\n",
    "    if 'low_high' in _kiwi.img_id:\n",
    "        img = _kiwi.dwi[40:90,20:70]   \n",
    "        ax[2].imshow(img,cmap='gray')\n",
    "        ax[2].set_title(_kiwi.img_id)\n",
    "    elif 'high.mat' in _kiwi.img_id:\n",
    "        img = _kiwi.dwi[70:160,40:120]   \n",
    "        ax[3].imshow(img,cmap='gray')\n",
    "        ax[3].set_title(_kiwi.img_id)\n",
    "    else:\n",
    "        img = _kiwi.dwi[40:90,20:70]   \n",
    "        ax[i].imshow(img,cmap='gray')\n",
    "        ax[i].set_title(_kiwi.img_id)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recon = np.zeros((128,128))\n",
    "model_input  = get_mgrid(128, 2).cuda()\n",
    "for i in range(9):\n",
    "    model_output = img_siren(model_input, i, 1/60.0)\n",
    "    mean_recon += model_output.cpu().view(128,128).detach().numpy()\n",
    "mean_recon /= 9\n",
    "#model_input  = get_mgrid(128, 2).cuda()\n",
    "#model_output = img_siren(model_input).cpu().view((128,128)).detach().numpy()\n",
    "fig, ax = plt.subplots(1,4, figsize=(24,6))\n",
    "ax[1].imshow(mean_recon, cmap='gray')\n",
    "ax[1].set_title('super resolution')\n",
    "ax[0].imshow(rescale(mean_img,2),cmap='gray')\n",
    "ax[0].set_title('mean image')\n",
    "\n",
    "for inx in range(len(kiwi_scans)):\n",
    "    _kiwi = kiwi_scans[inx]\n",
    "    if 'low_high' in _kiwi.img_id:\n",
    "        img = _kiwi.dwi[40:90,20:70]   \n",
    "        ax[2].imshow(rescale(img,2),cmap='gray')\n",
    "        ax[2].set_title('no motion')\n",
    "    elif 'high.mat' in _kiwi.img_id:\n",
    "        img = _kiwi.dwi[70:150,34:115]   \n",
    "        ax[3].imshow(img,cmap='gray')\n",
    "        ax[3].set_title('high resolution')\n",
    "for i in range(4):\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recon = np.zeros((128,128))\n",
    "model_input  = get_mgrid(128, 2).cuda()\n",
    "for i in range(9):\n",
    "    model_output = img_siren(model_input, i, 1/64.0)\n",
    "    mean_recon += model_output.cpu().view(128,128).detach().numpy()\n",
    "mean_recon /= 9\n",
    "#model_input  = get_mgrid(128, 2).cuda()\n",
    "#model_output = img_siren(model_input).cpu().view((128,128)).detach().numpy()\n",
    "fig, ax = plt.subplots(13,1,figsize=(6,72))\n",
    "ax[0].imshow(mean_recon, cmap='gray')\n",
    "ax[0].set_title('super')\n",
    "ax[1].imshow(mean_img,cmap='gray')\n",
    "ax[1].set_title('mean')\n",
    "i=4\n",
    "for inx in range(len(kiwi_scans)):\n",
    "    _kiwi = kiwi_scans[inx]\n",
    "    if 'low_high' in _kiwi.img_id:\n",
    "        img = _kiwi.dwi[40:90,20:70]   \n",
    "        ax[2].imshow(img,cmap='gray')\n",
    "        ax[2].set_title(_kiwi.img_id)\n",
    "    elif 'high.mat' in _kiwi.img_id:\n",
    "        img = _kiwi.dwi[70:160,40:120]   \n",
    "        ax[3].imshow(img,cmap='gray')\n",
    "        ax[3].set_title(_kiwi.img_id)\n",
    "    else:\n",
    "        img = _kiwi.dwi[40:90,20:70]   \n",
    "        ax[i].imshow(img,cmap='gray')\n",
    "        ax[i].set_title(_kiwi.img_id)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, pin_memory=True, num_workers=0)\n",
    "img_siren = Siren(in_features=2, out_features=1, \n",
    "                      hidden_features=128,\n",
    "                      hidden_layers=3, perturb=False)\n",
    "img_siren.cuda()\n",
    "torch.cuda.empty_cache()\n",
    "optim = torch.optim.Adam(lr=3e-4, params=img_siren.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params1 = list(img_siren.perturb_linear.parameters()) + list(img_siren.perturb_linear2.parameters())\n",
    "#optim1 = torch.optim.Adam(lr=3e-4, params=params1)\n",
    "#params2 = list(img_siren.net.parameters()) + list(img_siren.final_linear.parameters())\n",
    "#optim2 = torch.optim.Adam(lr=0.000001, params=params2)\n",
    "ctr = 0\n",
    "new_loss = 1000\n",
    "\n",
    "\n",
    "while True:\n",
    "    for sample in range(9):\n",
    "        ground_truth, model_input  = dataset.pixels[sample], dataset.coords[sample]\n",
    "        ground_truth, model_input = ground_truth.cuda(), model_input.cuda()\n",
    "        ground_truth /= ground_truth.max()\n",
    "        model_output = img_siren(model_input)\n",
    "        if not sample:\n",
    "            loss = ((model_output - ground_truth)**2).mean()\n",
    "        else:\n",
    "            loss += ((model_output - ground_truth)**2).mean()\n",
    "    optim.zero_grad()\n",
    "    #optim2.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    #optim2.step()\n",
    "    if loss.item() > new_loss and ctr>100:\n",
    "        break      \n",
    "    else:\n",
    "        new_loss = loss.item()\n",
    "    if not ctr%500:\n",
    "        print(new_loss)\n",
    "\n",
    "    ctr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_case.pt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_case = cases[0]\n",
    "seed = 0\n",
    "img_siren = Siren(in_features=2, out_features=1, \n",
    "                      hidden_features=128,\n",
    "                      hidden_layers=3, perturb=True)\n",
    "\n",
    "\n",
    "\n",
    "PATH = os.path.join('models', _case.pt_id + '_' + str(seed) + '.pt')\n",
    "img_siren.load_state_dict(torch.load(PATH))\n",
    "img_siren.cuda()\n",
    "\n",
    "_slice = _case.cancer_slice\n",
    "b = _case.b[3]\n",
    "b0 = _case.b0[:, :, _slice]\n",
    "dwi = _case.b3[:, :, _slice, :]\n",
    "img = np.mean(dwi,-1)\n",
    "mean_recon = np.zeros((128,128))\n",
    "model_input  = get_mgrid(128, 2).cuda()\n",
    "for i in range(_case.b3.shape[3]):\n",
    "    model_output = img_siren(model_input, i, 1.0/128.0)\n",
    "    mean_recon += model_output.cpu().view(128,128).detach().numpy()\n",
    "mean_recon /= _case.b3.shape[3]\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "axes[1].imshow(mean_recon)\n",
    "axes[0].imshow(img)\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "plt.show()\n",
    "print([round(x,3) for x in calculate_CNR_SNR(_case, img)])\n",
    "print([round(x,3) for x in calculate_CNR_SNR(_case, mean_recon)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc_in = calc_adc(img, _case.b0[:,:,_slice], _case.b[3])\n",
    "adc_out = calc_adc(mean_recon, _case.b0[:,:,_slice], _case.b[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print([round(x,2) for x in calculate_CNR_SNR(_case, adc_in)])\n",
    "print([round(x,2) for x in calculate_CNR_SNR(_case, adc_out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(18,18))\n",
    "ax[0].imshow(adc_in[35:95, 35:95], cmap='gray',vmin=0.0, vmax = 3)\n",
    "ax[1].imshow(adc_out[35:95, 35:95], cmap='gray',vmin=0.0,vmax=3)\n",
    "adc_out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_size = 512\n",
    "big_mean = np.zeros((big_size,big_size))\n",
    "model_input  = get_mgrid(big_size, 2).cuda()\n",
    "for i in range(_case.b3.shape[3]):\n",
    "    big_mean += img_siren(model_input, i, 1.0/128).cpu().view(big_size,big_size).detach().numpy()\n",
    "big_mean /= _case.b3.shape[3]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(25,25))\n",
    "axes[1].imshow(big_mean, cmap='gray')\n",
    "axes[0].imshow(rescale(img,4), cmap = 'gray')\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(25,25))\n",
    "axes[1].imshow(calc_adc(big_mean, rescale(b0,4), _case.b[3])[35*4:95*4,35*4:95*4], cmap='gray',vmin=0,vmax=3)\n",
    "axes[0].imshow(rescale(calc_adc(img, b0, _case.b[3]),4)[35*4:95*4,35*4:95*4], cmap = 'gray',vmin=0,vmax=3)\n",
    "axes[0].axis('off')\n",
    "axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
